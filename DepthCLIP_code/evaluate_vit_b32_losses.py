import os
import argparse
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import Compose, ToTensor, Resize, Normalize
from PIL import Image
from tqdm import tqdm
import numpy as np

# ğŸŸ  Ù…Ø¯Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯
from monoclip_vit_b32 import MonoCLIP_ViT_B32

# ---------------------------------------------------
# ğŸŸ  Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
# ---------------------------------------------------
class AverageMeter(object):
    def __init__(self, i=1, precision=4):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0
        self.i = i
        self.precision = precision

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

    def __str__(self):
        return f'{self.avg:.{self.precision}f}'

# ---------------------------------------------------
# ğŸŸ  ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªÙ…Ø§Ù… Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù‚
# ---------------------------------------------------
def compute_errors(gt, pred):
    thresh = torch.max((gt / pred), (pred / gt))
    a1 = (thresh < 1.25).float().mean()
    a2 = (thresh < 1.25 ** 2).float().mean()
    a3 = (thresh < 1.25 ** 3).float().mean()

    rmse = (gt - pred) ** 2
    rmse = torch.sqrt(rmse.mean())

    rmse_log = (torch.log(gt) - torch.log(pred)) ** 2
    rmse_log = torch.sqrt(rmse_log.mean())

    abs_rel = torch.mean(torch.abs(gt - pred) / gt)
    sq_rel = torch.mean(((gt - pred) ** 2) / gt)
    
    log10 = torch.mean(torch.abs(torch.log10(gt) - torch.log10(pred)))

    return {
        'abs_rel': abs_rel.item(), 'rmse': rmse.item(), 'log10': log10.item(),
        'a1': a1.item(), 'a2': a2.item(), 'a3': a3.item()
    }


# ---------------------------------------------------
# ğŸŸ  Ø¯ÛŒØªØ§Ø³Øª Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† ØµØ­ÛŒØ­ Ø¹Ù…Ù‚
# ---------------------------------------------------
class DepthDataset(Dataset):
    def __init__(self, root_dir, path_file, image_transform=None, depth_transform=None, depth_scale=1000.0):
        self.root_dir = root_dir
        self.image_transform = image_transform
        self.depth_transform = depth_transform
        self.depth_scale = depth_scale
        self.samples = []

        with open(path_file, 'r') as f:
            for line in f.readlines():
                rgb, depth = line.strip().split()
                self.samples.append((os.path.join(root_dir, rgb), os.path.join(root_dir, depth)))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        rgb_path, depth_path = self.samples[idx]
        image = Image.open(rgb_path).convert("RGB")
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¹Ù…Ù‚ Ø¨Ù‡ ØµÙˆØ±Øª ØµØ­ÛŒØ­ (uint16) Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªØ±
        depth = np.array(Image.open(depth_path), dtype=np.float32) / self.depth_scale
        depth = ToTensor()(depth)

        if self.image_transform:
            image = self.image_transform(image)
        if self.depth_transform:
            depth = self.depth_transform(depth)

        return image, depth

# ---------------------------------------------------
# ğŸŸ  ØªØ§Ø¨Ø¹ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒâ€ŒØ´Ø¯Ù‡
# ---------------------------------------------------
def evaluate(model, dataloader, device, cap=10.0, save_preds=False):
    model.eval()
    
    error_names = ['abs_rel', 'rmse', 'log10', 'a1', 'a2', 'a3']
    errors = {name: AverageMeter() for name in error_names}
    
    pred_list = []
    gt_list = []

    with torch.no_grad():
        for images, gt_depths in tqdm(dataloader, desc="Evaluating"):
            images = images.to(device)
            gt_depths = gt_depths.to(device)

            # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø§Ø³Ú© Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± (Ø¹Ù…Ù‚ ØµÙØ±)
            mask = (gt_depths > 1e-3) & (gt_depths < cap)

            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„
            preds = model(images)
            
            # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù‡Ù…â€ŒØ§Ù†Ø¯Ø§Ø²Ù‡ Ø¨ÙˆØ¯Ù† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ùˆ ÙˆØ§Ù‚Ø¹ÛŒØª
            preds = nn.functional.interpolate(
                preds, size=gt_depths.shape[-2:], mode='bilinear', align_corners=False
            )

            # Ø§Ø¹Ù…Ø§Ù„ Ú©Ù„Ø§Ù‡Ú© (cap) Ø±ÙˆÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
            preds[preds < 1e-3] = 1e-3
            preds[preds > cap] = cap
            
            # Ø¨Ø±Ø´ Garg Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
            h, w = gt_depths.shape[-2:]
            crop = (int(h * 0.40810811), int(h * 0.99189189),
                    int(w * 0.03594771), int(w * 0.96405229))
            
            gt_cropped = gt_depths[..., crop[0]:crop[1], crop[2]:crop[3]]
            pred_cropped = preds[..., crop[0]:crop[1], crop[2]:crop[3]]
            mask_cropped = mask[..., crop[0]:crop[1], crop[2]:crop[3]]

            # Ù…Ù‚ÛŒØ§Ø³â€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ Ù…ÛŒØ§Ù†Ù‡ (ÛŒÚ© Ø±ÙˆØ´ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯)
            median_scale = torch.median(gt_cropped[mask_cropped]) / torch.median(pred_cropped[mask_cropped])
            pred_cropped *= median_scale
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·Ø§Ù‡Ø§ ÙÙ‚Ø· Ø±ÙˆÛŒ Ù¾ÛŒÚ©Ø³Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø±
            gt_valid = gt_cropped[mask_cropped]
            pred_valid = pred_cropped[mask_cropped]

            batch_errors = compute_errors(gt_valid, pred_valid)
            for name in error_names:
                errors[name].update(batch_errors[name])

            if save_preds:
                pred_list.append(preds.cpu().numpy())
                gt_list.append(gt_depths.cpu().numpy())

    # Ú†Ø§Ù¾ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ
    print("\n" + "="*30)
    print("ğŸ“Š Final Evaluation Metrics (NYU Depth V2)")
    print("="*30)
    print(f"{'Metric':<10} | {'Value'}")
    print("-"*30)
    for name in error_names:
        print(f"{name:<10} | {errors[name].avg:.4f}")
    print("="*30)

    if save_preds:
        np.save("pred_depths.npy", np.concatenate(pred_list))
        np.save("gt_depths.npy", np.concatenate(gt_list))

# ---------------------------------------------------
# ğŸŸ  ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ (main)
# ---------------------------------------------------
def main(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    args.device = device

    # ØªØ¨Ø¯ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ± Ù…Ø´Ø§Ø¨Ù‡ CLIP
    image_transform = Compose([
        Resize((args.height, args.width), interpolation=Image.BICUBIC),
        ToTensor(),
        Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))
    ])

    val_dataset = DepthDataset(
        root_dir=args.val_data_root,
        path_file=args.val_data_path,
        image_transform=image_transform
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )

    model = MonoCLIP_ViT_B32(args)
    # â—ï¸ ØªÙˆØ¬Ù‡: Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ Ø¨Ø§ Ù…Ø¹Ù…Ø§Ø±ÛŒ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª
    model.load_state_dict(torch.load(args.model_path, map_location=device))
    model.to(device)

    evaluate(model, val_loader, device, save_preds=args.save_preds)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Depth Estimation Evaluation")
    parser.add_argument('--model_path', type=str, required=True, help='Path to the trained model file.')
    parser.add_argument('--val_data_root', type=str, required=True, help='Root directory of the validation data.')
    parser.add_argument('--val_data_path', type=str, required=True, help='Path to the text file listing validation files.')
    parser.add_argument('--batch_size', type=int, default=8, help='Batch size for evaluation.')
    parser.add_argument('--save_preds', action='store_true', help='If set, saves predictions and ground truth to .npy files.')
    
    # Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ù…Ø¯Ù„
    parser.add_argument('--height', type=int, default=224, help='Input image height for the model.')
    parser.add_argument('--width', type=int, default=224, help='Input image width for the model.')

    args = parser.parse_args()
    main(args)